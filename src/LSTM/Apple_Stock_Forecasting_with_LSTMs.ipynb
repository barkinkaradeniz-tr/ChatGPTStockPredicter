{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(os.path.expanduser(\"/Users/barkinkaradeniz/Projects/ChatGPTStockPredicter copy/\"))\n",
        "\n",
        "from src.mongo.pymongo_get_database import get_database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PSIHfWL23fBi",
        "outputId": "548a8b03-225f-4833-f543-c8956ec27c19"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dbname = get_database()\n",
        "appleChanges = dbname[\"AppleDailyStockData\"]\n",
        "appleSentimentAverages = dbname[\"AppleSentimentAverages\"]\n",
        "\n",
        "df = pd.DataFrame(list(appleChanges.find()))\n",
        "\n",
        "df[\"Sentiment\"] = [average[\"sentimentAverage\"] for average in appleSentimentAverages.find()]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "3I6ju2n83jGq",
        "outputId": "ffbaacb7-5393-4982-8726-a5f79b8a9fdd"
      },
      "outputs": [],
      "source": [
        "df = df[['Date', 'Close', 'Sentiment']]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCNhH5qH6Fc3",
        "outputId": "98de4ba4-c1f1-4696-c065-754a0cac0049"
      },
      "outputs": [],
      "source": [
        "df['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtzK_Fnd6UEP",
        "outputId": "bb06298a-412c-49f5-f830-0a7c7e857693"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "def str_to_datetime(s):\n",
        "  split = s.split('-')\n",
        "  year, month, day = int(split[0]), int(split[1]), int(split[2])\n",
        "  return datetime.datetime(year=year, month=month, day=day)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fE62iBCl-d_P",
        "outputId": "51fd791c-bda5-4375-be3f-a88efa479805"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0LJeyey_o6t",
        "outputId": "f4d3bf9d-417e-4bad-ec76-97415e50bdae"
      },
      "outputs": [],
      "source": [
        "df['Date'] = df['Date'].apply(str_to_datetime)\n",
        "df['Close'] = df['Close'].astype(float)\n",
        "df['Sentiment'] = df['Sentiment'].astype(float)\n",
        "\n",
        "df['Date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "khQN7tf1BJCB",
        "outputId": "09f6deea-48e4-4ed3-975b-fa261c7c8f35"
      },
      "outputs": [],
      "source": [
        "df.index = df.pop('Date')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "17OZExfcBWzD",
        "outputId": "d1e6868b-b04e-49b1-c7a1-cf4f705843ff"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df.index, df['Close'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(df.index, df['Sentiment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fsU9d3u0HdYj",
        "outputId": "10e55e21-f752-4d49-d7c2-ad01b39f2441"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3, m=5):\n",
        "  first_date = str_to_datetime(first_date_str)\n",
        "  last_date  = str_to_datetime(last_date_str)\n",
        "\n",
        "  target_date = first_date\n",
        "\n",
        "  dates = []\n",
        "  X, Y = [], []\n",
        "\n",
        "  last_time = False\n",
        "  while True:\n",
        "    df_subset = dataframe.loc[:target_date].tail(n+1)\n",
        "\n",
        "    if len(df_subset) != n+1:\n",
        "      print(f'Error: Window of size {n} is too large for date {target_date}')\n",
        "      return\n",
        "\n",
        "    values = df_subset['Close'].to_numpy()\n",
        "    x, y = values[:-1], values[-1]\n",
        "\n",
        "    dates.append(target_date)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "    next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
        "    next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
        "    next_date_str = next_datetime_str.split('T')[0]\n",
        "    year_month_day = next_date_str.split('-')\n",
        "    year, month, day = year_month_day\n",
        "    next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
        "\n",
        "    if last_time:\n",
        "      break\n",
        "\n",
        "    target_date = next_date\n",
        "\n",
        "    if target_date == last_date:\n",
        "      last_time = True\n",
        "\n",
        "  ret_df = pd.DataFrame({})\n",
        "  ret_df['Target Date'] = dates\n",
        "\n",
        "  X = np.array(X)\n",
        "  for i in range(0, n):\n",
        "    X[:, i]\n",
        "    ret_df[f'Target-{n-i}'] = X[:, i]\n",
        "\n",
        "##############################################################################################################  \n",
        "\n",
        "  target_date = first_date\n",
        "\n",
        "  X = []\n",
        "\n",
        "  last_time = False\n",
        "  while True:\n",
        "    df_subset = dataframe.loc[:target_date].tail(m)\n",
        "\n",
        "    if len(df_subset) != m:\n",
        "      print(f'Error: Window of size {m} is too large for date {target_date}')\n",
        "      return\n",
        "\n",
        "    values = df_subset['Sentiment'].to_numpy()\n",
        "\n",
        "    X.append(values)\n",
        "\n",
        "    next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
        "    next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
        "    next_date_str = next_datetime_str.split('T')[0]\n",
        "    year_month_day = next_date_str.split('-')\n",
        "    year, month, day = year_month_day\n",
        "    next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
        "\n",
        "    if last_time:\n",
        "      break\n",
        "\n",
        "    target_date = next_date\n",
        "\n",
        "    if target_date == last_date:\n",
        "      last_time = True\n",
        "\n",
        "  X = np.array(X)\n",
        "  for i in range(0, m):\n",
        "    X[:, i]\n",
        "    ret_df[f'Sentiment-{m-i-1}'] = X[:, i]\n",
        "\n",
        "##############################################################################################################\n",
        "\n",
        "  ret_df['Target'] = Y\n",
        "\n",
        "  return ret_df\n",
        "\n",
        "# Start day second time around: '2021-03-25'\n",
        "windowed_df = df_to_windowed_df(df,\n",
        "                                '2022-03-14',\n",
        "                                '2023-07-21',\n",
        "                                n=5,\n",
        "                                m=6)\n",
        "\n",
        "windowed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scX = StandardScaler()\n",
        "# scY = StandardScaler()\n",
        "\n",
        "# windowed_df.loc[:, windowed_df.columns[1:-1]] = scX.fit_transform(windowed_df.loc[:, windowed_df.columns[1:-1]])\n",
        "# windowed_df.loc[:, windowed_df.columns[-1]] = scY.fit_transform(windowed_df.loc[:, windowed_df.columns[-1]].values.reshape(-1, 1))\n",
        "\n",
        "# windowed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD17zIbaIZ6n",
        "outputId": "190e0356-1c59-4bdb-9aaa-002cf15aecd7"
      },
      "outputs": [],
      "source": [
        "def windowed_df_to_date_X_y(windowed_dataframe):\n",
        "  df_as_np = windowed_dataframe.to_numpy()\n",
        "\n",
        "  dates = df_as_np[:, 0]\n",
        "\n",
        "  middle_matrix = df_as_np[:, 1:-1]\n",
        "  X = middle_matrix.reshape((len(dates), middle_matrix.shape[1], 1))\n",
        "\n",
        "  Y = df_as_np[:, -1]\n",
        "\n",
        "  return dates, X.astype(np.float32), Y.astype(np.float32)\n",
        "\n",
        "dates, X, y = windowed_df_to_date_X_y(windowed_df)\n",
        "\n",
        "dates.shape, X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "LPHWfwZeMZSS",
        "outputId": "6d7b78be-84c4-4e17-9677-549d55e77ea4"
      },
      "outputs": [],
      "source": [
        "q_80 = int(len(dates) * .8)\n",
        "q_90 = int(len(dates) * .9)\n",
        "\n",
        "dates_train, X_train, y_train = dates[:q_80], X[:q_80], y[:q_80]\n",
        "\n",
        "dates_val, X_val, y_val = dates[q_80:q_90], X[q_80:q_90], y[q_80:q_90]\n",
        "dates_test, X_test, y_test = dates[q_90:], X[q_90:], y[q_90:]\n",
        "\n",
        "plt.plot(dates_train, y_train)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.plot(dates_test, y_test)\n",
        "\n",
        "plt.legend(['Train', 'Validation', 'Test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorboard.plugins.hparams import api as hp\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras import layers\n",
        "# import tensorflow as tf\n",
        "# # from helpers import *\n",
        "\n",
        "# HP_NUM_UNITS_LSTM = hp.HParam('Number of Hidden Neurons LSTM', hp.Discrete([32,64,128]))\n",
        "# HP_NUM_UNITS = hp.HParam('Number of Hidden Neurons', hp.Discrete([16,32,64]))\n",
        "# HP_LEARNING_RATE = hp.HParam('Learning Rate', hp.Discrete([0.0001, 0.001, 0.01]))\n",
        "# HP_BATCH_SIZE = hp.HParam('Batch Size', hp.Discrete([32, 64, 128]))\n",
        "# HP_NUM_LAYERS = hp.HParam('Number of Hidden Layers', hp.Discrete([2, 3]))\n",
        "# HP_NUM_EPOCHS = hp.HParam('Number of Epochs,', hp.Discrete([60, 100, 120]))\n",
        "\n",
        "# #Setting the Metric to MSE\n",
        "# METRIC_MSE = 'Validation Loss (MSE)'\n",
        "\n",
        "# #Creating & configuring log files\n",
        "# with tf.summary.create_file_writer('logs/HPT_secondStage').as_default():\n",
        "#   hp.hparams_config(\n",
        "#     hparams=[HP_NUM_UNITS_LSTM, HP_NUM_UNITS, HP_LEARNING_RATE, HP_BATCH_SIZE, HP_NUM_LAYERS, HP_NUM_EPOCHS],\n",
        "#     metrics=[hp.Metric(METRIC_MSE, display_name='Validation Loss (MSE)')]\n",
        "#   )\n",
        "\n",
        "# def train_test_model(hparams):\n",
        "#   model = tf.keras.models.Sequential()\n",
        "\n",
        "#   model.add(tf.keras.layers.Input((11, 1)))\n",
        "\n",
        "#   model.add(tf.keras.layers.LSTM(hparams[HP_NUM_UNITS_LSTM]))\n",
        "\n",
        "#   for _ in range(hparams[HP_NUM_LAYERS]):\n",
        "#     model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\")) \n",
        "\n",
        "#   model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "#   model.compile(\n",
        "#       optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE]),\n",
        "#       loss='mse',\n",
        "#       metrics=['mean_absolute_error'],\n",
        "#   )\n",
        "\n",
        "#   history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=hparams[HP_NUM_EPOCHS], batch_size=hparams[HP_BATCH_SIZE])\n",
        "#   best_mse = float('inf')\n",
        "#   for val_loss in history.history['val_loss']:\n",
        "#     if val_loss < best_mse:\n",
        "#       best_mse = val_loss\n",
        "#   print(best_mse)\n",
        "#   return best_mse\n",
        "\n",
        "# def run(run_dir, hparams):\n",
        "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
        "#       hp.hparams(hparams)  \n",
        "#       mse = train_test_model(hparams)\n",
        "#       tf.summary.scalar(METRIC_MSE, mse, step=1)\n",
        "\n",
        "# session_num = 00\n",
        "\n",
        "# for num_units_lstm in HP_NUM_UNITS_LSTM.domain.values:\n",
        "#     for num_units in HP_NUM_UNITS.domain.values:\n",
        "#         for learning_rate in HP_LEARNING_RATE.domain.values:\n",
        "#             for batch_size in HP_BATCH_SIZE.domain.values:\n",
        "#                 for num_layers in HP_NUM_LAYERS.domain.values:\n",
        "#                     for num_epochs in HP_NUM_EPOCHS.domain.values:\n",
        "#                         hparams = {\n",
        "#                             HP_NUM_UNITS_LSTM: num_units_lstm,\n",
        "#                             HP_NUM_UNITS: num_units,\n",
        "#                             HP_LEARNING_RATE: learning_rate,\n",
        "#                             HP_BATCH_SIZE: batch_size,\n",
        "#                             HP_NUM_LAYERS: num_layers,\n",
        "#                             HP_NUM_EPOCHS: num_epochs\n",
        "#                         }\n",
        "\n",
        "#                         run_name = \"run-%d\" % session_num\n",
        "#                         print('--- Starting trial: %s' % run_name)\n",
        "#                         print({h.name: hparams[h] for h in hparams})\n",
        "#                         run('logs/HPT_secondStage/Apple/' + run_name, hparams)\n",
        "#                         session_num += 1\n",
        "\n",
        "# # cmd+shift+p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGiLbQIYOawE",
        "outputId": "bcb769d6-d4c5-4522-e576-cd89ff64a067"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = Sequential([layers.Input((11, 1)),\n",
        "                    layers.LSTM(128),\n",
        "                    layers.Dense(64, activation='relu'),\n",
        "                    layers.Dense(64, activation='relu'),\n",
        "                    layers.Dense(1)])\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=Adam(learning_rate=0.01),\n",
        "              metrics=['mean_absolute_error'])\n",
        "\n",
        "results = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(results.history[\"loss\"])\n",
        "plt.plot(results.history[\"val_loss\"])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend(['Training Loss', 'Validation Loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_predictions = model.predict(X_train).flatten()\n",
        "val_predictions = model.predict(X_val).flatten()\n",
        "test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "# y_train = scY.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
        "# train_predictions = scY.inverse_transform(train_predictions.reshape(-1, 1)).flatten()\n",
        "# y_val = scY.inverse_transform(y_val.reshape(-1, 1)).flatten()\n",
        "# val_predictions = scY.inverse_transform(val_predictions.reshape(-1, 1)).flatten()\n",
        "# y_test = scY.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "# test_predictions = scY.inverse_transform(test_predictions.reshape(-1, 1)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "print('Test Mean Absolute Percentage Error:', mean_absolute_percentage_error(y_test, test_predictions))\n",
        "print(f'Test Mean Absolute Percentage Error: {np.mean(np.abs((y_test - test_predictions) / y_test)) * 100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "gG8eOTzEVl_X",
        "outputId": "93b02019-ae45-4c66-b604-835458210dfb"
      },
      "outputs": [],
      "source": [
        "plt.plot(dates_train, train_predictions)\n",
        "plt.plot(dates_train, y_train)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend(['Training Predictions', 'Training Observations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UrRaAUbnWBhE",
        "outputId": "ddb80173-dfd5-485d-e1fd-ab643b7b6433"
      },
      "outputs": [],
      "source": [
        "plt.plot(dates_val, val_predictions)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend(['Validation Predictions', 'Validation Observations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "wF5sDSxVWLFd",
        "outputId": "cf54dd02-18b9-4666-8cd0-c8f2320e80b9"
      },
      "outputs": [],
      "source": [
        "plt.plot(dates_test, test_predictions)\n",
        "plt.plot(dates_test, y_test)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend(['Testing Predictions', 'Testing Observations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8b-JsTvEWfAm",
        "outputId": "169e03e9-020b-4062-fc23-6d1bc37792a3"
      },
      "outputs": [],
      "source": [
        "plt.plot(dates_train, train_predictions)\n",
        "plt.plot(dates_train, y_train)\n",
        "plt.plot(dates_val, val_predictions)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.plot(dates_test, test_predictions)\n",
        "plt.plot(dates_test, y_test)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.legend(['Training Predictions',\n",
        "            'Training Observations',\n",
        "            'Validation Predictions',\n",
        "            'Validation Observations',\n",
        "            'Testing Predictions',\n",
        "            'Testing Observations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_value_y = y_val[-1]\n",
        "\n",
        "y_test_binary = np.zeros_like(y_test)\n",
        "test_predictions_binary = np.zeros_like(test_predictions)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if y_test[i] > last_value_y:\n",
        "        y_test_binary[i] = 1\n",
        "    else:\n",
        "        y_test_binary[i] = 0\n",
        "\n",
        "    if test_predictions[i] > last_value_y:\n",
        "        test_predictions_binary[i] = 1\n",
        "    else:\n",
        "        test_predictions_binary[i] = 0\n",
        "\n",
        "    last_value_y = y_test[i]\n",
        "\n",
        "print(np.concatenate((y_test_binary.reshape(len(y_test),1), test_predictions_binary.reshape(len(test_predictions_binary),1)),1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test_binary, test_predictions_binary)\n",
        "print(cm)\n",
        "accuracy_score(y_test_binary, test_predictions_binary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
