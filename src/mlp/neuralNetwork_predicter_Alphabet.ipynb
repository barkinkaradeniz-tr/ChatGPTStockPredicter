{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicter Neural Network "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser(\"/Users/barkinkaradeniz/Projects/ChatGPTStockPredicter copy/\"))\n",
    "\n",
    "from src.mongo.pymongo_get_database import get_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from datetime import datetime  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = get_database()\n",
    "averages = dbname[\"AlphabetSentimentAveragesUpdated\"]\n",
    "changes = dbname[\"AlphabetDailyChange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((337, 10))\n",
    "X[:, 0] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-07\"}}, {\"date\" : {\"$lte\" : \"2023-07-10\"}}]})])\n",
    "X[:, 1] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-08\"}}, {\"date\" : {\"$lte\" : \"2023-07-11\"}}]})])\n",
    "X[:, 2] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-09\"}}, {\"date\" : {\"$lte\" : \"2023-07-12\"}}]})])\n",
    "X[:, 3] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-10\"}}, {\"date\" : {\"$lte\" : \"2023-07-13\"}}]})])\n",
    "X[:, 4] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-11\"}}, {\"date\" : {\"$lte\" : \"2023-07-14\"}}]})])\n",
    "X[:, 5] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-14\"}}, {\"date\" : {\"$lte\" : \"2023-07-17\"}}]})])\n",
    "X[:, 6] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-15\"}}, {\"date\" : {\"$lte\" : \"2023-07-18\"}}]})])\n",
    "X[:, 7] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-16\"}}, {\"date\" : {\"$lte\" : \"2023-07-19\"}}]})])\n",
    "X[:, 8] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-17\"}}, {\"date\" : {\"$lte\" : \"2023-07-20\"}}]})])\n",
    "X[:, 9] = np.array([average[\"sentimentAverage\"] for average in averages.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-18\"}}, {\"date\" : {\"$lte\" : \"2023-07-21\"}}]})])\n",
    "\n",
    "# X[:, 10] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-07\"}}, {\"date\" : {\"$lte\" : \"2023-07-10\"}}]})])\n",
    "# X[:, 11] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-08\"}}, {\"date\" : {\"$lte\" : \"2023-07-11\"}}]})])\n",
    "# X[:, 12] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-09\"}}, {\"date\" : {\"$lte\" : \"2023-07-12\"}}]})])\n",
    "# X[:, 13] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-10\"}}, {\"date\" : {\"$lte\" : \"2023-07-13\"}}]})])\n",
    "# X[:, 14] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-11\"}}, {\"date\" : {\"$lte\" : \"2023-07-14\"}}]})])\n",
    "# X[:, 15] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-14\"}}, {\"date\" : {\"$lte\" : \"2023-07-17\"}}]})])\n",
    "# X[:, 16] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-15\"}}, {\"date\" : {\"$lte\" : \"2023-07-18\"}}]})])\n",
    "# X[:, 17] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-16\"}}, {\"date\" : {\"$lte\" : \"2023-07-19\"}}]})])\n",
    "# X[:, 18] = np.array([change[\"change\"] for change in changes.find({\"$and\" : [{\"date\": {\"$gte\" : \"2022-03-17\"}}, {\"date\" : {\"$lte\" : \"2023-07-20\"}}]})])\n",
    "\n",
    "y = np.array([change[\"change\"] for change in changes.find({\"date\": {\"$gte\" : \"2022-03-18\"}})])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# model = CatBoostClassifier(\n",
    "#     iterations=200,\n",
    "#     learning_rate=0.02,\n",
    "#     depth=12,\n",
    "#     eval_metric=\"Accuracy\",\n",
    "#     random_seed = 2112,\n",
    "#     bagging_temperature = 0.2,\n",
    "#     od_type=\"Iter\",\n",
    "#     od_wait=100,\n",
    "#     verbose=0,\n",
    "#     task_type=\"CPU\"\n",
    "# )\n",
    "\n",
    "\n",
    "# scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.02,\n",
    "    depth=12,\n",
    "    eval_metric=\"Accuracy\",\n",
    "    random_seed = 2112,\n",
    "    bagging_temperature = 0.2,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=100,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.add(tf.keras.layers.Dense(units=10, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
